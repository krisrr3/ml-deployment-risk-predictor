{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment Risk Profile Prediction: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Predict the risk profile of a deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to business scenario\n",
    "\n",
    "Change management teams, processes and forums struggle to keep up in large organisations.\n",
    "\n",
    "This solution will provide a prediction on the risk profile which would negate the need for committees to review changes from every team across the whole organisation.\n",
    "\n",
    "If the risk profile comes up as LOW, teams should be allowed to proceed by default. If the risk profile comes up as MEDIM or HIGH, the standard committes apply.\n",
    "\n",
    "But the insights that cause the risks to be MEDIUM or HIGH, should constantly be identified and discussed with relevant stakeholders to increase velocity in an organisation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "**Data columns**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- `incidents`: capturing data on past incidents per business unit, department and system\n",
    "- `documentation`: capturing how many times developers read strategy, architecture and design documents\n",
    "- `Architecture catalog`:  is the feature change being made on a strategic asset vs a legacy asset\n",
    "- `work management tool (e.g from Jira)`:  there is a lot that can be captured there. But ideally: the date a feature is created, the date it is completed\n",
    "- `source control`:  capturing commits per feature\n",
    "- `CI`:  capturing build data for features\n",
    "- `CD`:  capturing deployment data for features per environment\n",
    "- `Testing data`:  capturing test execution data and test result data for features\n",
    "- `ITSM data (e.g from ServiceNow)`:  capture change management data\n",
    "- `Logging`:  capturing date when a feature is actually consumed by a real Customer\n",
    "- `Monitoring`:  capturing stability data of a system after a feature is deployed\n",
    "\n",
    "**Data format**\n",
    "- Tab `\\t` separated text file, without quote or escape characters\n",
    "- First line in each file is header; 1 line corresponds to 1 record\n",
    "\n",
    "### Data standard\n",
    "\n",
    "Not yet defined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data collection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Now that we have decided where to focus our energy, let's set things up so you can start working on solving the problem.\n",
    "\n",
    "**Note:** This notebook was created and tested on an `ml.m4.xlarge` notebook instance. \n",
    "\n",
    "Start by specifying:\n",
    "- The Amazon Simple Storage Service (Amazon S3) bucket and prefix(?) that you want to use for training and model data. This should be within the same Region as the Notebook Instance, training, and hosting.\n",
    "- The AWS Identity and Access Management (IAM) role [Amazon Resource Name (ARN)](https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html) used to give training and hosting access to your data. See the documentation for how to create these.\n",
    "\n",
    "**Note:** If more than one role is required for notebook instances, training, and/or hosting, replace the `get_execution_role()` call with the appropriate full IAM role ARN string(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace **`<DataBucketName>`** with the resource name that was provided with your lab account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the bucket and prefix according to your information\n",
    "bucket = '<DataBucketName>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%pip install --upgrade boto3 -q\n",
    "%pip install mxnet -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "import boto3\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "prefix = 'sagemaker-fm' \n",
    "\n",
    "# Add this to display all the outputs in the cell and not just the last one\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data preprocessing and visualization  \n",
    "In this data preprocessing phase, you should take the opportunity to explore and visualize your data to better understand it. First, import the necessary libraries and read the data into a Pandas dataframe. After that, explore your data. Look for the shape of the dataset and explore your columns and the types of columns you're working with (numerical, categorical). Consider performing basic statistics on the features to get a sense of feature means and ranges. Take a close look at your target column and determine its distribution.\n",
    "\n",
    "### Specific questions to consider\n",
    "1. What can you deduce from the basic statistics you ran on the features? \n",
    "\n",
    "2. What can you deduce from the distributions of the target classes?\n",
    "\n",
    "3. Is there anything else you deduced from exploring the data?\n",
    "\n",
    "#### <span style=\"color: blue;\">Project presentation: Include a summary of your answers to these and other similar questions in your project presentations.</span>\n",
    "\n",
    "Start by bringing in the dataset from an Amazon S3 public bucket to this notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['mkdir', '-p', '/home/ec2-user/SageMaker/project/data/AmazonReviews'], returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz to ../project/data/AmazonReviews/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['aws', 's3', 'cp', 's3://amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz', '/home/ec2-user/SageMaker/project/data/AmazonReviews'], returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether the file is already in the desired path or if it needs to be downloaded\n",
    "\n",
    "base_path = '/home/ec2-user/SageMaker/project/data/DeploymentRiskProfile'\n",
    "file_path = '/Company_Deployment_Data.tsv.gz'\n",
    "\n",
    "if not os.path.isfile(base_path + file_path):\n",
    "    subprocess.run(['mkdir', '-p', base_path])\n",
    "    subprocess.run(['aws', 's3', 'cp', 's3://DeploymentRiskProfile/tsv' + file_path, base_path])\n",
    "else:\n",
    "    print('File already downloaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset\n",
    "\n",
    "Read the data into a Pandas dataframe so that you can know what you are dealing with.\n",
    "\n",
    "**Note:** You'll set `error_bad_lines=False` when reading the file in, because there appear to be a very small number of records that would create a problem otherwise.\n",
    "\n",
    "**Hint:** You can use the built-in Python `read_csv` function ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)). You can use the file path directly with Pandas `read_csv` with `delimiter='\\t'`.\n",
    "\n",
    "For example: `pd.read_csv('filename.tar.gz', delimiter = '\\t', error_bad_lines=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(base_path + file_path, \n",
    "                 delimiter='\\t',\n",
    "                 on_bad_lines=\"skip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first few rows of your dataset.\n",
    "\n",
    "**Hint**: Use the `pandas.head(<number>)` function to print the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>12190288</td>\n",
       "      <td>R3FU16928EP5TC</td>\n",
       "      <td>B00AYB1482</td>\n",
       "      <td>668895143</td>\n",
       "      <td>Enlightened: Season 1</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>I loved it and I wish there was a season 3</td>\n",
       "      <td>I loved it and I wish there was a season 3... ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>30549954</td>\n",
       "      <td>R1IZHHS1MH3AQ4</td>\n",
       "      <td>B00KQD28OM</td>\n",
       "      <td>246219280</td>\n",
       "      <td>Vicious</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>As always it seems that the best shows come fr...</td>\n",
       "      <td>As always it seems that the best shows come fr...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>52895410</td>\n",
       "      <td>R52R85WC6TIAH</td>\n",
       "      <td>B01489L5LQ</td>\n",
       "      <td>534732318</td>\n",
       "      <td>After Words</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Charming movie</td>\n",
       "      <td>This movie isn't perfect, but it gets a lot of...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent   \n",
       "0          US     12190288  R3FU16928EP5TC  B00AYB1482       668895143  \\\n",
       "1          US     30549954  R1IZHHS1MH3AQ4  B00KQD28OM       246219280   \n",
       "2          US     52895410   R52R85WC6TIAH  B01489L5LQ       534732318   \n",
       "\n",
       "           product_title        product_category  star_rating  helpful_votes   \n",
       "0  Enlightened: Season 1  Digital_Video_Download            5              0  \\\n",
       "1                Vicious  Digital_Video_Download            5              0   \n",
       "2            After Words  Digital_Video_Download            4             17   \n",
       "\n",
       "   total_votes vine verified_purchase   \n",
       "0            0    N                 Y  \\\n",
       "1            0    N                 Y   \n",
       "2           18    N                 Y   \n",
       "\n",
       "                                     review_headline   \n",
       "0         I loved it and I wish there was a season 3  \\\n",
       "1  As always it seems that the best shows come fr...   \n",
       "2                                     Charming movie   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0  I loved it and I wish there was a season 3... ...  2015-08-31  \n",
       "1  As always it seems that the best shows come fr...  2015-08-31  \n",
       "2  This movie isn't perfect, but it gets a lot of...  2015-08-31  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what is the information contained in all the columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anatomy of the dataset\n",
    "\n",
    "Get a little more comfortable with the data and see what features are at hand.\n",
    "\n",
    "** Data sciencetist input required here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing and processing the dataset\n",
    "\n",
    "#### Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How many rows and columns do you have in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of the dataset.  \n",
    "\n",
    "**Hint**: Use the `<dataframe>.shape` function to check the size of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3998345, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: (3998345,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Which columns contain null values, and how many null values do they contain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a summary of the dataset.\n",
    "\n",
    "**Hint**: Use `<dataframe>.info` function using the keyword arguments `null_counts = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3998345 entries, 0 to 3998344\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Dtype \n",
      "---  ------             ----- \n",
      " 0   marketplace        object\n",
      " 1   customer_id        int64 \n",
      " 2   review_id          object\n",
      " 3   product_id         object\n",
      " 4   product_parent     int64 \n",
      " 5   product_title      object\n",
      " 6   product_category   object\n",
      " 7   star_rating        int64 \n",
      " 8   helpful_votes      int64 \n",
      " 9   total_votes        int64 \n",
      " 10  vine               object\n",
      " 11  verified_purchase  object\n",
      " 12  review_headline    object\n",
      " 13  review_body        object\n",
      " 14  review_date        object\n",
      "dtypes: int64(5), object(10)\n",
      "memory usage: 457.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Review headline: 25, Review_body: 78, Review_date: 138"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Are there any duplicate rows? If yes, how many are there?\n",
    "\n",
    "**Hint**: Filter the dataframe using `dataframe.duplicated()` ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html#pandas.DataFrame.duplicated)) and check the length of the new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df[df.duplicated()]\n",
    "\n",
    "len(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** There are no duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data preprocessing\n",
    "\n",
    "Now it's time to decide what features you are going to use and how you are going to prepare them for your model. For this example, limit yourself to `system_id`, `incident_no`, `asset_type`, `test_run_id`, `test_result`, and `feature_id`. Including additional features in the recommendation system could be beneficial but would require substantial processing (particularly the text data), which would be beyond the scope of this notebook.\n",
    "\n",
    "Reduce this dataset and only use the columns mentioned.\n",
    "\n",
    "**Hint:** Select multiple columns as a dataframe by passing the columns as a list. For example: `df[['column_name 1', 'column_name 2']]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = df[['system_id', 'incident_no', 'asset_type', 'test_run_id', 'test_result']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if you have duplicates after reducing the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df_reduced[df_reduced.duplicated()]\n",
    "\n",
    "len(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: 131"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why do you have duplicates in your dataset now? What changed after you reduced the dataset? Review the first 20 lines of the duplicates.\n",
    "\n",
    "**Hint**: Use the `pandas.head(<number>)` function to print the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>product_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>565194</th>\n",
       "      <td>41454255</td>\n",
       "      <td>B00Y2UYRFS</td>\n",
       "      <td>1</td>\n",
       "      <td>unseen 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594322</th>\n",
       "      <td>17570065</td>\n",
       "      <td>B00R3EEO2G</td>\n",
       "      <td>2</td>\n",
       "      <td>The Maze Runner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611264</th>\n",
       "      <td>15703996</td>\n",
       "      <td>B00I3MQNWG</td>\n",
       "      <td>5</td>\n",
       "      <td>Bosch Season 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612471</th>\n",
       "      <td>28456429</td>\n",
       "      <td>B008Y6W7J4</td>\n",
       "      <td>5</td>\n",
       "      <td>Rabbit Hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613791</th>\n",
       "      <td>52388381</td>\n",
       "      <td>B00YORA25I</td>\n",
       "      <td>5</td>\n",
       "      <td>McFarland, USA (Theatrical)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685156</th>\n",
       "      <td>31828958</td>\n",
       "      <td>B00TT53YSW</td>\n",
       "      <td>5</td>\n",
       "      <td>Bates Motel, Season 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204110</th>\n",
       "      <td>19462</td>\n",
       "      <td>B00QWUL4AW</td>\n",
       "      <td>5</td>\n",
       "      <td>Exodus: Gods and Kings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564816</th>\n",
       "      <td>24892653</td>\n",
       "      <td>B00L2GPYKW</td>\n",
       "      <td>5</td>\n",
       "      <td>The Escape Artist Season 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601662</th>\n",
       "      <td>44513234</td>\n",
       "      <td>B00NY4UIKG</td>\n",
       "      <td>5</td>\n",
       "      <td>The Equalizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616429</th>\n",
       "      <td>43345475</td>\n",
       "      <td>B00P5968FC</td>\n",
       "      <td>3</td>\n",
       "      <td>The Babadook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616584</th>\n",
       "      <td>20779855</td>\n",
       "      <td>B00O99GXPE</td>\n",
       "      <td>5</td>\n",
       "      <td>Max Lucado's The Christmas Candle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617034</th>\n",
       "      <td>52861226</td>\n",
       "      <td>B00Q4FMCDS</td>\n",
       "      <td>2</td>\n",
       "      <td>The November Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618497</th>\n",
       "      <td>735926</td>\n",
       "      <td>B00IQBE0BU</td>\n",
       "      <td>3</td>\n",
       "      <td>Once Upon A Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618598</th>\n",
       "      <td>3283400</td>\n",
       "      <td>B000NPQ0II</td>\n",
       "      <td>4</td>\n",
       "      <td>Creator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618822</th>\n",
       "      <td>50380731</td>\n",
       "      <td>B00C58TGQ4</td>\n",
       "      <td>3</td>\n",
       "      <td>Hemingway &amp; Gellhorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618896</th>\n",
       "      <td>5465295</td>\n",
       "      <td>B009AP2B9Y</td>\n",
       "      <td>5</td>\n",
       "      <td>Kickin' It Volume 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619053</th>\n",
       "      <td>39849456</td>\n",
       "      <td>B0035LN5YO</td>\n",
       "      <td>5</td>\n",
       "      <td>Gallipoli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620635</th>\n",
       "      <td>22158610</td>\n",
       "      <td>B00M0HXNPK</td>\n",
       "      <td>5</td>\n",
       "      <td>Transcendence (2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621358</th>\n",
       "      <td>46543213</td>\n",
       "      <td>B005OPTSIQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Workaholics Season 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621751</th>\n",
       "      <td>25315183</td>\n",
       "      <td>B00NEFWXNK</td>\n",
       "      <td>5</td>\n",
       "      <td>Arrow: Season 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         customer_id  product_id  star_rating   \n",
       "565194      41454255  B00Y2UYRFS            1  \\\n",
       "594322      17570065  B00R3EEO2G            2   \n",
       "611264      15703996  B00I3MQNWG            5   \n",
       "612471      28456429  B008Y6W7J4            5   \n",
       "613791      52388381  B00YORA25I            5   \n",
       "685156      31828958  B00TT53YSW            5   \n",
       "1204110        19462  B00QWUL4AW            5   \n",
       "1564816     24892653  B00L2GPYKW            5   \n",
       "1601662     44513234  B00NY4UIKG            5   \n",
       "1616429     43345475  B00P5968FC            3   \n",
       "1616584     20779855  B00O99GXPE            5   \n",
       "1617034     52861226  B00Q4FMCDS            2   \n",
       "1618497       735926  B00IQBE0BU            3   \n",
       "1618598      3283400  B000NPQ0II            4   \n",
       "1618822     50380731  B00C58TGQ4            3   \n",
       "1618896      5465295  B009AP2B9Y            5   \n",
       "1619053     39849456  B0035LN5YO            5   \n",
       "1620635     22158610  B00M0HXNPK            5   \n",
       "1621358     46543213  B005OPTSIQ            5   \n",
       "1621751     25315183  B00NEFWXNK            5   \n",
       "\n",
       "                             product_title  \n",
       "565194                            unseen 2  \n",
       "594322                     The Maze Runner  \n",
       "611264                      Bosch Season 1  \n",
       "612471                         Rabbit Hole  \n",
       "613791         McFarland, USA (Theatrical)  \n",
       "685156               Bates Motel, Season 3  \n",
       "1204110             Exodus: Gods and Kings  \n",
       "1564816         The Escape Artist Season 1  \n",
       "1601662                      The Equalizer  \n",
       "1616429                       The Babadook  \n",
       "1616584  Max Lucado's The Christmas Candle  \n",
       "1617034                   The November Man  \n",
       "1618497                 Once Upon A Forest  \n",
       "1618598                            Creator  \n",
       "1618822               Hemingway & Gellhorn  \n",
       "1618896                Kickin' It Volume 3  \n",
       "1619053                          Gallipoli  \n",
       "1620635               Transcendence (2014)  \n",
       "1621358               Workaholics Season 2  \n",
       "1621751                    Arrow: Season 3  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint:** Take a look at the first two elements in the duplicates dataframe, and query the original dataframe df to see what the data looks like. You can use the `query` function ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html)).\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "df_eg = pd.DataFrame({\n",
    "            'A': [1,2,3,4],\n",
    "            'B': [\n",
    "        })\n",
    "df_eg.query('A > 1 & B > 0')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing, remove the duplicate rows.\n",
    "\n",
    "**Hint**: Use the `~` operator to select all the rows that aren't duplicated. For example:\n",
    "    \n",
    "```\n",
    "df_eg = pd.DataFrame({\n",
    "            'A': [1,2,3,4],\n",
    "            'B': [2,0,5,2]\n",
    "        })\n",
    "df_eg[~(df_eg['B'] > 0)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = df_reduced[~df_reduced.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize some of the rows in the dataset\n",
    "If you haven't done so in the above, you can use the space below to further visualize some of your data. Look specifically at the distribution of features like `test_result`, `incident_id`, and `asset_type`.\n",
    "\n",
    "**Specific questions to consider**\n",
    "\n",
    "1. After looking at the distributions of features, to what extent might those features help your model? Is there anything you can deduce from those distributions that might be helpful in better understanding your data? \n",
    "\n",
    "2. Should you use all the data? What features should you use?\n",
    "\n",
    "3. What month has the highest count of user ratings?\n",
    "\n",
    "Use the cells below to visualize your data and answer these and other questions that might be of interest to you. Insert and delete cells where needed.\n",
    "\n",
    "#### <span style=\"color: blue;\">Project presentation: Include a summary of your answers to these and similar questions in your project presentations.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `sns.barplot` ([documentation](https://seaborn.pydata.org/generated/seaborn.barplot.html)) to plot the `star_rating` density and distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Question:** What month contains the highest count of incidents?\n",
    "\n",
    "**Hint**:  \n",
    "1. Use `pd.to_datetime` to convert the `review_date` column to a datetime column.  \n",
    "2. Use the month from the `review_date` column. You can access it for a datetime column using `<column_name>.dt.month`.\n",
    "3. Use the `groupby` function using `idxmax`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
